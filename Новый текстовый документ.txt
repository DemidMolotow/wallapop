Microsoft Windows [Version 10.0.19043.1052]
(c) Корпорация Майкрософт (Microsoft Corporation). Все права защищены.

C:\Users\Vitalya>cdC:\Users\Vitalya\Desktop\trahatelwallapope
Синтаксическая ошибка в имени файла, имени папки или метке тома.

C:\Users\Vitalya>cd C:\Users\Vitalya\Desktop\trahatelwallapope

C:\Users\Vitalya\Desktop\trahatelwallapope>venv/Script/activate
"venv" не является внутренней или внешней
командой, исполняемой программой или пакетным файлом.

C:\Users\Vitalya\Desktop\trahatelwallapope>.venv/Script/activate
".venv" не является внутренней или внешней
командой, исполняемой программой или пакетным файлом.

C:\Users\Vitalya\Desktop\trahatelwallapope>venv
"venv" не является внутренней или внешней
командой, исполняемой программой или пакетным файлом.

C:\Users\Vitalya\Desktop\trahatelwallapope>venv\Scripts\activate

(venv) C:\Users\Vitalya\Desktop\trahatelwallapope>python test_groq_only.py
Open Interpreter will require approval before running code.

Use interpreter -y to bypass this.

Press CTRL-C to exit.

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 725, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 608, in completion
    return self.streaming(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 896, in streaming
    headers, response = self.make_sync_openai_chat_completion_request(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 149, in sync_wrapper
    result = func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 471, in make_sync_openai_chat_completion_request
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 453, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1896, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1869, in completion
    response = openai_chat_completions.completion(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 736, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\respond.py", line 87, in respond
    for chunk in interpreter.llm.run(messages_for_llm):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 322, in run
    yield from run_tool_calling_llm(self, params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\run_tool_calling_llm.py", line 178, in run_tool_calling_llm
    for chunk in llm.completions(**request_params):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 466, in fixed_litellm_completions
    raise first_error  # If all attempts fail, raise the first error
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 443, in fixed_litellm_completions
    yield from litellm.completion(**params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1285, in wrapper
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1163, in wrapper
    result = original_function(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 3304, in completion
    raise exception_type(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2271, in exception_type
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 301, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenAIException - You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\test_groq_only.py", line 11, in <module>
    print(oi.chat("Скажи привет на русском!"))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 191, in chat
    for _ in self._streaming_chat(message=message, display=display):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 223, in _streaming_chat
    yield from terminal_interface(self, message)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\terminal_interface\terminal_interface.py", line 162, in terminal_interface
    for chunk in interpreter.chat(message, display=False, stream=True):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 259, in _streaming_chat
    yield from self._respond_and_store()
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 318, in _respond_and_store
    for chunk in respond(self):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\respond.py", line 121, in respond
    display_markdown_message(
NameError: name 'display_markdown_message' is not defined

(venv) C:\Users\Vitalya\Desktop\trahatelwallapope>pip install --upgrade open-interpreter
Requirement already satisfied: open-interpreter in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (0.4.3)
Requirement already satisfied: anthropic<0.38.0,>=0.37.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (0.37.1)
Requirement already satisfied: astor<0.9.0,>=0.8.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (0.8.1)
Requirement already satisfied: git-python<2.0.0,>=1.0.3 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (1.0.3)
Requirement already satisfied: google-generativeai<0.8.0,>=0.7.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (0.7.2)
Requirement already satisfied: html2image<3.0.0.0,>=2.0.4.3 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (2.0.7)
Requirement already satisfied: html2text<2025.0.0,>=2024.2.26 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (2024.2.26)
Requirement already satisfied: inquirer<4.0.0,>=3.1.3 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (3.4.0)
Requirement already satisfied: ipykernel<7.0.0,>=6.26.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (6.29.5)
Requirement already satisfied: jupyter-client<9.0.0,>=8.6.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (8.6.3)
Requirement already satisfied: litellm<2.0.0,>=1.41.26 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (1.72.6.post1)
Requirement already satisfied: matplotlib<4.0.0,>=3.8.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (3.10.3)
Requirement already satisfied: platformdirs<5.0.0,>=4.2.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (4.3.8)
Requirement already satisfied: psutil<6.0.0,>=5.9.6 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (5.9.8)
Requirement already satisfied: pydantic<3.0.0,>=2.6.4 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (2.11.7)
Requirement already satisfied: pyperclip<2.0.0,>=1.9.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (1.9.0)
Requirement already satisfied: pyreadline3<4.0.0,>=3.4.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (3.5.4)
Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (6.0.2)
Requirement already satisfied: rich<14.0.0,>=13.4.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (13.9.4)
Requirement already satisfied: selenium<5.0.0,>=4.24.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (4.33.0)
Requirement already satisfied: send2trash<2.0.0,>=1.8.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (1.8.3)
Requirement already satisfied: setuptools in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (65.5.0)
Requirement already satisfied: shortuuid<2.0.0,>=1.0.13 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (1.0.13)
Requirement already satisfied: six<2.0.0,>=1.16.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (1.17.0)
Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (0.37.2)
Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (0.7.0)
Requirement already satisfied: tokentrim<0.2.0,>=0.1.13 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (0.1.13)
Requirement already satisfied: toml<0.11.0,>=0.10.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (0.10.2)
Requirement already satisfied: typer<0.13.0,>=0.12.5 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (0.12.5)
Requirement already satisfied: webdriver-manager<5.0.0,>=4.0.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (4.0.2)
Requirement already satisfied: wget<4.0,>=3.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (3.2)
Requirement already satisfied: yaspin<4.0.0,>=3.0.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from open-interpreter) (3.1.0)
Requirement already satisfied: anyio<5,>=3.5.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (4.9.0)
Requirement already satisfied: distro<2,>=1.7.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (1.9.0)
Requirement already satisfied: httpx<1,>=0.23.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (0.25.2)
Requirement already satisfied: jiter<1,>=0.4.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (0.10.0)
Requirement already satisfied: sniffio in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (1.3.1)
Requirement already satisfied: tokenizers>=0.13.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (0.21.1)
Requirement already satisfied: typing-extensions<5,>=4.7 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (4.13.2)
Requirement already satisfied: exceptiongroup>=1.0.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from anyio<5,>=3.5.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (1.3.0)
Requirement already satisfied: idna>=2.8 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from anyio<5,>=3.5.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (3.10)
Requirement already satisfied: gitpython in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from git-python<2.0.0,>=1.0.3->open-interpreter) (3.1.44)
Requirement already satisfied: google-ai-generativelanguage==0.6.6 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-generativeai<0.8.0,>=0.7.1->open-interpreter) (0.6.6)
Requirement already satisfied: google-api-core in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-generativeai<0.8.0,>=0.7.1->open-interpreter) (2.25.1)
Requirement already satisfied: google-api-python-client in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-generativeai<0.8.0,>=0.7.1->open-interpreter) (2.172.0)
Requirement already satisfied: google-auth>=2.15.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-generativeai<0.8.0,>=0.7.1->open-interpreter) (2.40.3)
Requirement already satisfied: protobuf in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-generativeai<0.8.0,>=0.7.1->open-interpreter) (4.25.8)
Requirement already satisfied: tqdm in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-generativeai<0.8.0,>=0.7.1->open-interpreter) (4.67.1)
Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (1.26.1)
Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (1.70.0)
Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (2.32.4)
Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (1.73.0)
Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (1.62.3)
Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (5.5.2)
Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (0.4.2)
Requirement already satisfied: rsa<5,>=3.1.4 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (4.9.1)
Requirement already satisfied: websocket-client~=1.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from html2image<3.0.0.0,>=2.0.4.3->open-interpreter) (1.8.0)
Requirement already satisfied: certifi in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from httpx<1,>=0.23.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (2025.6.15)
Requirement already satisfied: httpcore==1.* in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from httpx<1,>=0.23.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (1.0.9)
Requirement already satisfied: h11>=0.16 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (0.16.0)
Requirement already satisfied: blessed>=1.19.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from inquirer<4.0.0,>=3.1.3->open-interpreter) (1.21.0)
Requirement already satisfied: editor>=1.6.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from inquirer<4.0.0,>=3.1.3->open-interpreter) (1.6.6)
Requirement already satisfied: readchar>=4.2.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from inquirer<4.0.0,>=3.1.3->open-interpreter) (4.2.1)
Requirement already satisfied: comm>=0.1.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (0.2.2)
Requirement already satisfied: debugpy>=1.6.5 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (1.8.14)
Requirement already satisfied: ipython>=7.23.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (8.37.0)
Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (5.8.1)
Requirement already satisfied: matplotlib-inline>=0.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (0.1.7)
Requirement already satisfied: nest-asyncio in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (1.6.0)
Requirement already satisfied: packaging in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (25.0)
Requirement already satisfied: pyzmq>=24 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (27.0.0)
Requirement already satisfied: tornado>=6.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (6.5.1)
Requirement already satisfied: traitlets>=5.4.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (5.14.3)
Requirement already satisfied: python-dateutil>=2.8.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from jupyter-client<9.0.0,>=8.6.0->open-interpreter) (2.9.0.post0)
Requirement already satisfied: aiohttp in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (3.11.18)
Requirement already satisfied: click in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (8.2.1)
Requirement already satisfied: importlib-metadata>=6.8.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (8.7.0)
Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (3.1.6)
Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (4.24.0)
Requirement already satisfied: openai>=1.68.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (1.88.0)
Requirement already satisfied: python-dotenv>=0.2.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (1.1.0)
Requirement already satisfied: MarkupSafe>=2.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.41.26->open-interpreter) (3.0.2)
Requirement already satisfied: attrs>=22.2.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.41.26->open-interpreter) (25.3.0)
Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.41.26->open-interpreter) (2025.4.1)
Requirement already satisfied: referencing>=0.28.4 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.41.26->open-interpreter) (0.36.2)
Requirement already satisfied: rpds-py>=0.7.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.41.26->open-interpreter) (0.25.1)
Requirement already satisfied: contourpy>=1.0.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (1.3.2)
Requirement already satisfied: cycler>=0.10 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (4.58.4)
Requirement already satisfied: kiwisolver>=1.3.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (1.4.8)
Requirement already satisfied: numpy>=1.23 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (2.2.6)
Requirement already satisfied: pillow>=8 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (11.2.1)
Requirement already satisfied: pyparsing>=2.3.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (3.2.3)
Requirement already satisfied: annotated-types>=0.6.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from pydantic<3.0.0,>=2.6.4->open-interpreter) (0.7.0)
Requirement already satisfied: pydantic-core==2.33.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from pydantic<3.0.0,>=2.6.4->open-interpreter) (2.33.2)
Requirement already satisfied: typing-inspection>=0.4.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from pydantic<3.0.0,>=2.6.4->open-interpreter) (0.4.1)
Requirement already satisfied: charset_normalizer<4,>=2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (3.4.2)
Requirement already satisfied: urllib3<3,>=1.21.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (2.4.0)
Requirement already satisfied: markdown-it-py>=2.2.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from rich<14.0.0,>=13.4.2->open-interpreter) (3.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from rich<14.0.0,>=13.4.2->open-interpreter) (2.19.1)
Requirement already satisfied: pyasn1>=0.1.3 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (0.6.1)
Requirement already satisfied: trio~=0.30.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from selenium<5.0.0,>=4.24.0->open-interpreter) (0.30.0)
Requirement already satisfied: trio-websocket~=0.12.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from selenium<5.0.0,>=4.24.0->open-interpreter) (0.12.2)
Requirement already satisfied: regex>=2022.1.18 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from tiktoken<0.8.0,>=0.7.0->open-interpreter) (2024.11.6)
Requirement already satisfied: sortedcontainers in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from trio~=0.30.0->selenium<5.0.0,>=4.24.0->open-interpreter) (2.4.0)
Requirement already satisfied: outcome in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from trio~=0.30.0->selenium<5.0.0,>=4.24.0->open-interpreter) (1.3.0.post0)
Requirement already satisfied: cffi>=1.14 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from trio~=0.30.0->selenium<5.0.0,>=4.24.0->open-interpreter) (1.17.1)
Requirement already satisfied: wsproto>=0.14 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from trio-websocket~=0.12.2->selenium<5.0.0,>=4.24.0->open-interpreter) (1.2.0)
Requirement already satisfied: shellingham>=1.3.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from typer<0.13.0,>=0.12.5->open-interpreter) (1.5.4)
Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from urllib3[socks]~=2.4.0->selenium<5.0.0,>=4.24.0->open-interpreter) (1.7.1)
Requirement already satisfied: termcolor<2.4.0,>=2.2.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from yaspin<4.0.0,>=3.0.2->open-interpreter) (2.3.0)
Requirement already satisfied: wcwidth>=0.1.4 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from blessed>=1.19.0->inquirer<4.0.0,>=3.1.3->open-interpreter) (0.2.13)
Requirement already satisfied: jinxed>=1.1.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from blessed>=1.19.0->inquirer<4.0.0,>=3.1.3->open-interpreter) (1.3.0)
Requirement already satisfied: pycparser in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from cffi>=1.14->trio~=0.30.0->selenium<5.0.0,>=4.24.0->open-interpreter) (2.22)
Requirement already satisfied: colorama in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from click->litellm<2.0.0,>=1.41.26->open-interpreter) (0.4.6)
Requirement already satisfied: runs in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from editor>=1.6.0->inquirer<4.0.0,>=3.1.3->open-interpreter) (1.2.2)
Requirement already satisfied: xmod in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from editor>=1.6.0->inquirer<4.0.0,>=3.1.3->open-interpreter) (1.8.1)
Requirement already satisfied: zipp>=3.20 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.41.26->open-interpreter) (3.23.0)
Requirement already satisfied: decorator in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (5.2.1)
Requirement already satisfied: jedi>=0.16 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (0.19.2)
Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (3.0.51)
Requirement already satisfied: stack_data in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (0.6.3)
Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (0.8.4)
Requirement already satisfied: ansicon in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from jinxed>=1.1.0->blessed>=1.19.0->inquirer<4.0.0,>=3.1.3->open-interpreter) (1.89.0)
Requirement already satisfied: pywin32>=300 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel<7.0.0,>=6.26.0->open-interpreter) (310)
Requirement already satisfied: mdurl~=0.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.4.2->open-interpreter) (0.1.2)
Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from tokenizers>=0.13.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (0.33.0)
Requirement already satisfied: filelock in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (3.18.0)
Requirement already satisfied: fsspec>=2023.5.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (2025.5.1)
Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (2.6.1)
Requirement already satisfied: aiosignal>=1.1.2 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (1.3.2)
Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (5.0.1)
Requirement already satisfied: frozenlist>=1.1.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (1.7.0)
Requirement already satisfied: multidict<7.0,>=4.5 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (6.5.0)
Requirement already satisfied: propcache>=0.2.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (0.3.2)
Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (1.20.1)
Requirement already satisfied: gitdb<5,>=4.0.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from gitpython->git-python<2.0.0,>=1.0.3->open-interpreter) (4.0.12)
Requirement already satisfied: smmap<6,>=3.0.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from gitdb<5,>=4.0.1->gitpython->git-python<2.0.0,>=1.0.3->open-interpreter) (5.0.2)
Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (0.22.0)
Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (0.2.0)
Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (4.2.0)
Requirement already satisfied: executing>=1.2.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from stack_data->ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (2.2.0)
Requirement already satisfied: asttokens>=2.1.0 in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from stack_data->ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (3.0.0)
Requirement already satisfied: pure-eval in c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages (from stack_data->ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (0.2.3)

(venv) C:\Users\Vitalya\Desktop\trahatelwallapope>set | findstr OI_

(venv) C:\Users\Vitalya\Desktop\trahatelwallapope>set | findstr OPENAI

(venv) C:\Users\Vitalya\Desktop\trahatelwallapope>set | findstr GROQ

(venv) C:\Users\Vitalya\Desktop\trahatelwallapope>python test_groq_only.py
OI_PROVIDER: groq
OI_MODEL: llama3-70b-8192
GROQ_API_KEY: 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
Open Interpreter will require approval before running code.

Use interpreter -y to bypass this.

Press CTRL-C to exit.

LiteLLM requires an API key. Trying again with a dummy API key. In the future, if this fixes it, please set a dummy API key to prevent this message. (e.g `interpreter --api_key x` or `self.api_key = 'x'`)
Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 725, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 608, in completion
    return self.streaming(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 896, in streaming
    headers, response = self.make_sync_openai_chat_completion_request(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 149, in sync_wrapper
    result = func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 471, in make_sync_openai_chat_completion_request
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 453, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1896, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1869, in completion
    response = openai_chat_completions.completion(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 736, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\respond.py", line 87, in respond
    for chunk in interpreter.llm.run(messages_for_llm):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 322, in run
    yield from run_tool_calling_llm(self, params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\run_tool_calling_llm.py", line 178, in run_tool_calling_llm
    for chunk in llm.completions(**request_params):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 466, in fixed_litellm_completions
    raise first_error  # If all attempts fail, raise the first error
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 443, in fixed_litellm_completions
    yield from litellm.completion(**params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1285, in wrapper
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1163, in wrapper
    result = original_function(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 3304, in completion
    raise exception_type(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2271, in exception_type
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 434, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\test_groq_only.py", line 17, in <module>
    print(oi.chat("Скажи привет на русском!"))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 191, in chat
    for _ in self._streaming_chat(message=message, display=display):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 223, in _streaming_chat
    yield from terminal_interface(self, message)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\terminal_interface\terminal_interface.py", line 162, in terminal_interface
    for chunk in interpreter.chat(message, display=False, stream=True):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 259, in _streaming_chat
    yield from self._respond_and_store()
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 318, in _respond_and_store
    for chunk in respond(self):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\respond.py", line 113, in respond
    raise Exception(
Exception: Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 725, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 608, in completion
    return self.streaming(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 896, in streaming
    headers, response = self.make_sync_openai_chat_completion_request(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 149, in sync_wrapper
    result = func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 471, in make_sync_openai_chat_completion_request
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 453, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1896, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1869, in completion
    response = openai_chat_completions.completion(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 736, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\respond.py", line 87, in respond
    for chunk in interpreter.llm.run(messages_for_llm):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 322, in run
    yield from run_tool_calling_llm(self, params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\run_tool_calling_llm.py", line 178, in run_tool_calling_llm
    for chunk in llm.completions(**request_params):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 466, in fixed_litellm_completions
    raise first_error  # If all attempts fail, raise the first error
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 443, in fixed_litellm_completions
    yield from litellm.completion(**params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1285, in wrapper
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1163, in wrapper
    result = original_function(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 3304, in completion
    raise exception_type(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2271, in exception_type
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 434, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.


There might be an issue with your API key(s).

To reset your API key (we'll use OPENAI_API_KEY for this example, but you may need to reset your ANTHROPIC_API_KEY, HUGGINGFACE_API_KEY, etc):
        Mac/Linux: 'export OPENAI_API_KEY=your-key-here'. Update your ~/.zshrc on MacOS or ~/.bashrc on Linux with the new key if it has already been persisted there.,
        Windows: 'setx OPENAI_API_KEY your-key-here' then restart terminal.



(venv) C:\Users\Vitalya\Desktop\trahatelwallapope>pip show open-interpreter
Name: open-interpreter
Version: 0.4.3
Summary: Let language models run code
Home-page:
Author: Killian Lucas
Author-email: killian@openinterpreter.com
License:
Location: c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages
Requires: anthropic, astor, git-python, google-generativeai, html2image, html2text, inquirer, ipykernel, jupyter-client, litellm, matplotlib, platformdirs, psutil, pydantic, pyperclip, pyreadline3, pyyaml, rich, selenium, send2trash, setuptools, shortuuid, six, starlette, tiktoken, tokentrim, toml, typer, webdriver-manager, wget, yaspin
Required-by:

(venv) C:\Users\Vitalya\Desktop\trahatelwallapope>pip show litellm
Name: litellm
Version: 1.72.6.post1
Summary: Library to easily interface with LLM API providers
Home-page: https://litellm.ai
Author: BerriAI
Author-email:
License: MIT
Location: c:\users\vitalya\desktop\trahatelwallapope\venv\lib\site-packages
Requires: aiohttp, click, httpx, importlib-metadata, jinja2, jsonschema, openai, pydantic, python-dotenv, tiktoken, tokenizers
Required-by: open-interpreter

(venv) C:\Users\Vitalya\Desktop\trahatelwallapope>cd C:\Users\Vitalya\Desktop\asd

(venv) C:\Users\Vitalya\Desktop\asd>python test_groq_only.py
OI_PROVIDER: groq
OI_MODEL: llama3-70b-8192
GROQ_API_KEY: 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
Open Interpreter will require approval before running code.

Use interpreter -y to bypass this.

Press CTRL-C to exit.

LiteLLM requires an API key. Trying again with a dummy API key. In the future, if this fixes it, please set a dummy API key to prevent this message. (e.g `interpreter --api_key x` or `self.api_key = 'x'`)
Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 725, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 608, in completion
    return self.streaming(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 896, in streaming
    headers, response = self.make_sync_openai_chat_completion_request(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 149, in sync_wrapper
    result = func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 471, in make_sync_openai_chat_completion_request
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 453, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1896, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1869, in completion
    response = openai_chat_completions.completion(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 736, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\respond.py", line 87, in respond
    for chunk in interpreter.llm.run(messages_for_llm):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 322, in run
    yield from run_tool_calling_llm(self, params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\run_tool_calling_llm.py", line 178, in run_tool_calling_llm
    for chunk in llm.completions(**request_params):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 466, in fixed_litellm_completions
    raise first_error  # If all attempts fail, raise the first error
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 443, in fixed_litellm_completions
    yield from litellm.completion(**params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1285, in wrapper
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1163, in wrapper
    result = original_function(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 3304, in completion
    raise exception_type(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2271, in exception_type
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 434, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\asd\test_groq_only.py", line 17, in <module>
    print(oi.chat("Скажи привет на русском!"))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 191, in chat
    for _ in self._streaming_chat(message=message, display=display):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 223, in _streaming_chat
    yield from terminal_interface(self, message)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\terminal_interface\terminal_interface.py", line 162, in terminal_interface
    for chunk in interpreter.chat(message, display=False, stream=True):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 259, in _streaming_chat
    yield from self._respond_and_store()
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 318, in _respond_and_store
    for chunk in respond(self):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\respond.py", line 113, in respond
    raise Exception(
Exception: Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 725, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 608, in completion
    return self.streaming(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 896, in streaming
    headers, response = self.make_sync_openai_chat_completion_request(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 149, in sync_wrapper
    result = func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 471, in make_sync_openai_chat_completion_request
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 453, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1896, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1869, in completion
    response = openai_chat_completions.completion(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 736, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\respond.py", line 87, in respond
    for chunk in interpreter.llm.run(messages_for_llm):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 322, in run
    yield from run_tool_calling_llm(self, params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\run_tool_calling_llm.py", line 178, in run_tool_calling_llm
    for chunk in llm.completions(**request_params):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 466, in fixed_litellm_completions
    raise first_error  # If all attempts fail, raise the first error
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 443, in fixed_litellm_completions
    yield from litellm.completion(**params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1285, in wrapper
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1163, in wrapper
    result = original_function(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 3304, in completion
    raise exception_type(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2271, in exception_type
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 434, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.


There might be an issue with your API key(s).

To reset your API key (we'll use OPENAI_API_KEY for this example, but you may need to reset your ANTHROPIC_API_KEY, HUGGINGFACE_API_KEY, etc):
        Mac/Linux: 'export OPENAI_API_KEY=your-key-here'. Update your ~/.zshrc on MacOS or ~/.bashrc on Linux with the new key if it has already been persisted there.,
        Windows: 'setx OPENAI_API_KEY your-key-here' then restart terminal.



(venv) C:\Users\Vitalya\Desktop\asd>cd C:\Users\Vitalya\Desktop\trahatelwallapope

(venv) C:\Users\Vitalya\Desktop\trahatelwallapope>python test_groq_only.py
OI_PROVIDER: groq
OI_MODEL: llama3-70b-8192
GROQ_API_KEY: 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
Open Interpreter will require approval before running code.

Use interpreter -y to bypass this.

Press CTRL-C to exit.

LiteLLM requires an API key. Trying again with a dummy API key. In the future, if this fixes it, please set a dummy API key to prevent this message. (e.g `interpreter --api_key x` or `self.api_key = 'x'`)
Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 725, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 608, in completion
    return self.streaming(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 896, in streaming
    headers, response = self.make_sync_openai_chat_completion_request(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 149, in sync_wrapper
    result = func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 471, in make_sync_openai_chat_completion_request
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 453, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1896, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1869, in completion
    response = openai_chat_completions.completion(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 736, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\respond.py", line 87, in respond
    for chunk in interpreter.llm.run(messages_for_llm):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 322, in run
    yield from run_tool_calling_llm(self, params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\run_tool_calling_llm.py", line 178, in run_tool_calling_llm
    for chunk in llm.completions(**request_params):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 466, in fixed_litellm_completions
    raise first_error  # If all attempts fail, raise the first error
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 443, in fixed_litellm_completions
    yield from litellm.completion(**params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1285, in wrapper
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1163, in wrapper
    result = original_function(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 3304, in completion
    raise exception_type(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2271, in exception_type
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 434, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\test_groq_only.py", line 17, in <module>
    print(oi.chat("Скажи привет на русском!"))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 191, in chat
    for _ in self._streaming_chat(message=message, display=display):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 223, in _streaming_chat
    yield from terminal_interface(self, message)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\terminal_interface\terminal_interface.py", line 162, in terminal_interface
    for chunk in interpreter.chat(message, display=False, stream=True):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 259, in _streaming_chat
    yield from self._respond_and_store()
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\core.py", line 318, in _respond_and_store
    for chunk in respond(self):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\respond.py", line 113, in respond
    raise Exception(
Exception: Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 725, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 608, in completion
    return self.streaming(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 896, in streaming
    headers, response = self.make_sync_openai_chat_completion_request(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 149, in sync_wrapper
    result = func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 471, in make_sync_openai_chat_completion_request
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 453, in make_sync_openai_chat_completion_request
    raw_response = openai_client.chat.completions.with_raw_response.create(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1896, in completion
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 1869, in completion
    response = openai_chat_completions.completion(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\llms\openai\openai.py", line 736, in completion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\respond.py", line 87, in respond
    for chunk in interpreter.llm.run(messages_for_llm):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 322, in run
    yield from run_tool_calling_llm(self, params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\run_tool_calling_llm.py", line 178, in run_tool_calling_llm
    for chunk in llm.completions(**request_params):
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 466, in fixed_litellm_completions
    raise first_error  # If all attempts fail, raise the first error
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\interpreter\core\llm\llm.py", line 443, in fixed_litellm_completions
    yield from litellm.completion(**params)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1285, in wrapper
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\utils.py", line 1163, in wrapper
    result = original_function(*args, **kwargs)
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\main.py", line 3304, in completion
    raise exception_type(
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2271, in exception_type
    raise e
  File "C:\Users\Vitalya\Desktop\trahatelwallapope\venv\lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 434, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: sk-proj-.... You can find your API key at https://platform.openai.com/account/api-keys.


There might be an issue with your API key(s).

To reset your API key (we'll use OPENAI_API_KEY for this example, but you may need to reset your ANTHROPIC_API_KEY, HUGGINGFACE_API_KEY, etc):
        Mac/Linux: 'export OPENAI_API_KEY=your-key-here'. Update your ~/.zshrc on MacOS or ~/.bashrc on Linux with the new key if it has already been persisted there.,
        Windows: 'setx OPENAI_API_KEY your-key-here' then restart terminal.



(venv) C:\Users\Vitalya\Desktop\trahatelwallapope>






